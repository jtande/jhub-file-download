{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnLOmERSFZD2"
   },
   "source": [
    "# Notebook 3: Texture classification\n",
    "\n",
    "An important topic in computer vision is to classify textures based only on photos. Many different algorithms exist for this pretty hard machine learning problem. \n",
    "\n",
    "In this notebook, we'll try and use persistent homology to classify textures. This exercise was inspired by [this](https://openaccess.thecvf.com/content_CVPRW_2020/papers/w50/Chung_Smooth_Summaries_of_Persistence_Diagrams_and_Texture_Classification_CVPRW_2020_paper.pdf) recent paper (by people here at UNCG!), which is actually very readable so go check it out if you're interested. That paper uses more advanced techniques that what we'll use here, but the basic idea comes through. The textures we will use are from the classic Brodatz texture dataset. \n",
    "\n",
    "This Notebook has **three compulsory Exercises**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfpL8EjaFvZ8"
   },
   "source": [
    "First let's install gudhi and an optimal transport library we'll need later too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JlHx-6y0Fy-Z",
    "outputId": "2d78e113-7362-4298-bd0f-5f82abef598f"
   },
   "outputs": [],
   "source": [
    "!pip install gudhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7eGbH32STGtc",
    "outputId": "7b512439-90f4-488e-9248-4364821b500c"
   },
   "outputs": [],
   "source": [
    "!pip install pot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRgzD-1GF4jI"
   },
   "source": [
    "Make sure you still have the texture data from last time in your home directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NCe1wi42F9QW"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import gudhi\n",
    "import gudhi.wasserstein\n",
    "import gudhi.hera\n",
    "import numpy as np\n",
    "import ot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yb019GgQKqj7"
   },
   "source": [
    "Here is a function that uses everything we saw in Notebook 2. It takes in an array representing an image, and outputs the persistence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YRLu1IEZK0HG"
   },
   "outputs": [],
   "source": [
    "def image_persistence(array, dimension):\n",
    "  height, width = array.shape\n",
    "  cubeComplex = gudhi.CubicalComplex(\n",
    "      dimensions = [width,height],\n",
    "      top_dimensional_cells = 255 - array.flatten()\n",
    "  )\n",
    "  cubeComplex.compute_persistence()\n",
    "  persistence = cubeComplex.persistence_intervals_in_dimension(dimension)\n",
    "  return persistence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lfn7KDwq78HD"
   },
   "source": [
    "## Bottleneck distance with Gudhi\n",
    "Let's learn how to compute bottleneck distance with `gudhi`. As an example, we'll take the top left corners of the `sandhe.tiff` and `barkhe.tiff` images and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "RSQ7gzUW8F44",
    "outputId": "d51f35dc-e6ae-4fee-8463-f1c04af2c84b"
   },
   "outputs": [],
   "source": [
    "#sand\n",
    "sand_image = Image.open(\"./tda-texture-exercise/sandhe.tiff\")\n",
    "sand_array = np.array(sand_image)\n",
    "top_left_corner_of_sand =  sand_array[0:100,0:100]\n",
    "plt.imshow(top_left_corner_of_sand, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "#bark\n",
    "bark_image = Image.open(\"./tda-texture-exercise/barkhe.tiff\")\n",
    "bark_array = np.array(bark_image)\n",
    "top_left_corner_of_bark =  bark_array[0:100,0:100]\n",
    "plt.imshow(top_left_corner_of_bark, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62EGFeKy89HN"
   },
   "source": [
    "We can use our function above to get their persistence diagrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622
    },
    "id": "q6Af-Lik9KNR",
    "outputId": "cc54d2da-1c93-4df7-c09c-da0a8d6156f9"
   },
   "outputs": [],
   "source": [
    "#sand\n",
    "sand_persistence = image_persistence(top_left_corner_of_sand, dimension=0)\n",
    "gudhi.plot_persistence_diagram(sand_persistence)\n",
    "\n",
    "#bark\n",
    "bark_persistence = image_persistence(top_left_corner_of_bark, dimension=0)\n",
    "gudhi.plot_persistence_diagram(bark_persistence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GK6Y00ed9bL6"
   },
   "source": [
    "We're going to use the function `gudhi.bottleneck_distance`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "veHIPnEC-FaW",
    "outputId": "3097a239-5c0f-4380-e16c-4afb211439e8"
   },
   "outputs": [],
   "source": [
    "gudhi.bottleneck_distance(\n",
    "    sand_persistence, bark_persistence\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OfRaUJWr-NSu"
   },
   "source": [
    "Let's compare this distance to the distance between the top left corner of `sandhe.png` and the bottom right corner of the same image. Should it be higher or lower than the distance between sand and bark? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TR_rhWjv-XJM",
    "outputId": "f490775b-379b-4e56-f846-e5701a478411"
   },
   "outputs": [],
   "source": [
    "#get the bottom right corner\n",
    "sand_image = Image.open(\"./tda-texture-exercise/sandhe.tiff\")\n",
    "sand_array = np.array(sand_image)\n",
    "bottom_right_corner_of_sand =  sand_array[400:500,400:500]\n",
    "#get the persistence\n",
    "bottom_right_sand_persistence = image_persistence(bottom_right_corner_of_sand, dimension=0)\n",
    "#get the bottleneck distance to the top left corner of sand\n",
    "gudhi.bottleneck_distance(\n",
    "    sand_persistence,\n",
    "    bottom_right_sand_persistence\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yeosH76dRp5c"
   },
   "source": [
    "Is this what you were expecting? What does this tell you about the bottleneck distance as a measure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIxe02pD_FWP"
   },
   "source": [
    "## Exercise 1: Matching corners with bottleneck distance\n",
    "Can persistence match top-left 100x100 corners to bottom-right 100x100 corners? **Fill in the ... below** to write code to find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KIK8gVPD_bBG"
   },
   "outputs": [],
   "source": [
    "#let's record the image names\n",
    "image_names = [\n",
    "  'sandhe.tiff', 'grasshe.tiff', 'brickhe.tiff', 'weavehe.tiff','woodhe.tiff','bubbleshe.tiff','barkhe.tiff'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YsbGbtdF_fEV"
   },
   "outputs": [],
   "source": [
    "#let's collect the top left and bottom right corners of our images\n",
    "#into two lists named top_left_corner_images and bottom_right_corner_images\n",
    "top_left_corner_images = []\n",
    "bottom_right_corner_images = []\n",
    "for image_name in image_names:\n",
    "  image = Image.open(\"./tda-texture-exercise/{}\".format(image_name))\n",
    "  image_array = np.array(image)\n",
    "  top_left_corner_image = image_array[...,...]\n",
    "  top_left_corner_images.append(top_left_corner_image)\n",
    "  bottom_right_corner_image = image_array[...,...]\n",
    "  bottom_right_corner_images.append(bottom_right_corner_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3HeD5sMCAaTb"
   },
   "outputs": [],
   "source": [
    "#okay now let's match each top left corner to it's closest match from \n",
    "#the bottom right corners\n",
    "for n in range(len(image_names)):\n",
    "  #get the persistence of the nth top left corner\n",
    "  top_left_persistence = image_persistence(...)\n",
    "  #get the bottleneck distance to all the bottom right corners\n",
    "  distances_to_bottom_right_corners = []\n",
    "  for m in range(len(image_names)):\n",
    "    bottom_right_persistence = image_persistence(...)\n",
    "    distance = gudhi.bottleneck_distance(\n",
    "      ...,\n",
    "      ...\n",
    "    )\n",
    "    distances_to_bottom_right_corners.append(distance)\n",
    "  #now we have a list of distances, let's find the minimum one\n",
    "  best_match = np.argmin(distances_to_bottom_right_corners)\n",
    "  #and print the results\n",
    "  print(\"The top left corner of the image {}\".format(image_names[n]))\n",
    "  print(\"was matched to the bottom right corner of the image {}.\".format(image_names[best_match]))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_S69YXE1B4WO"
   },
   "source": [
    "How did we do? Did all the top-left corners find their bottom-right partners?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLVd9vHqCj4G"
   },
   "source": [
    "## Wasserstein distances\n",
    "Bottleneck distance is often criticized (including in this class!) for being too insensitive. Let's try this again, but with a p-Wasserstein distance instead of a bottleneck distance. Recall that the p-Wasserstein distance is a version of bottleneck distance that replaces the maximums with vector norms. \n",
    "\n",
    "`gudhi` has at least one decent implementation of p-Wasserstein distances, which we'll show now. We still have `sand_persistence` and `bark_persistence` as variables (hopefully -- if you don't just run the first few blocks of code again), so we'll use those.\n",
    "\n",
    "The `order` and `internal_p` refer to the exponents in the Wasserstein distance. We'll set both to 1 to get the 1-Wasserstein distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FJdfJcMoCs2C",
    "outputId": "0574fda4-81af-481c-cbc3-f4c202fe50a1"
   },
   "outputs": [],
   "source": [
    "gudhi.hera.wasserstein_distance(\n",
    "    sand_persistence,\n",
    "    bark_persistence,\n",
    "    order = 1,\n",
    "    internal_p = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8p0-8lTrDFNy"
   },
   "source": [
    "Remember, the Wasserstein distance cannot be directly compared to bottleneck, since it's a sum not a max. \n",
    "\n",
    "Let's look at the two corners of sand again. Do we see a better result than with bottleneck distance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bv0gcjWhQ1Qn",
    "outputId": "ad2bfce6-5d1a-46c2-a914-97766936386a"
   },
   "outputs": [],
   "source": [
    "#get the bottom right corner\n",
    "sand_image = Image.open(\"./tda-texture-exercise/sandhe.tiff\")\n",
    "sand_array = np.array(sand_image)\n",
    "bottom_right_corner_of_sand =  sand_array[400:500,400:500]\n",
    "#get the persistence\n",
    "bottom_right_sand_persistence = image_persistence(bottom_right_corner_of_sand, dimension=0)\n",
    "#get the bottleneck distance to the top left corner of sand\n",
    "gudhi.hera.wasserstein_distance(\n",
    "    sand_persistence,\n",
    "    bottom_right_sand_persistence,\n",
    "    order = 1,\n",
    "    internal_p = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2D2u52rCIh5"
   },
   "source": [
    "## Exercise 2: Using Wasserstein distance\n",
    "In the code blocks below, **repeat Question 1 except this time use 1-Wasserstein distance**. Does it do better than the bottleneck distance? Or does it do better for some images and not in others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xN0A2-1-Cg1Q"
   },
   "outputs": [],
   "source": [
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TMKZt_ORQgX"
   },
   "source": [
    "## Exercise 3: Using Wasserstein distance and 1 dimensional homology\n",
    "In the code blocks below, **repeat Exercise 2 except this time use 1 dimensional persistent homology**. How do the results compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eiJPwv8URb3p"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a training set for the challenge questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of taking just two pieces of every image (the top-left and bottom-right corners), we could take more. Let's say we take 5 100x100 patches of each image. That gives us a dataset of 35 images with labels. Let's call this the 'training set'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = []\n",
    "for image_name in image_names:\n",
    "    full_image = Image.open(\"./tda-texture-exercise/{}\".format(image_name))\n",
    "    full_image_array = np.array(full_image)\n",
    "    for i in range(5):\n",
    "        training_set.append(full_image_array[100*i:100*(i+1), 100*i:100*(i+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also make some labels which correspond to this training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels = []\n",
    "for image_name in image_names:\n",
    "    training_labels.extend([image_name]*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GM-emCaWI7jq"
   },
   "source": [
    "# Challenge questions\n",
    "\n",
    "- Create a distance matrix $M$ such that the $(i,j)^{th}$ entry of $M$ is the Wasserstein distance between the diagrams for image $i$ and image $j$ in `training_set`. Give this matrix to the clustering algorithm DBSCAN (see [here](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html) for details and an example) and see if it correctly finds the 7 clusters. Remember to use `metric=precomputed` in your DBSCAN function.\n",
    "\n",
    "- Build a function `classify_texture` that takes any image and returns the label of the closest match in the training set (by Wasserstein distance). You should be able to adapt some of the code above. Try your function out on the bottom _left_ corners and see if it finds the right labels.\n",
    "\n",
    "- For each texture, generate the persistence landscapes for the five examples of that texture in the training set and plot them on top of each other. Do the persistence landscapes for different textures look different?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Challenge questions\n",
    "\n",
    "If you already like and know machine learning, then you've probably noticed you have a huge number of ways to use the above to build a texture classifier. Feel free to try some of them out, and you can even reuse what you create in your mini-project later on. Possible ideas include:\n",
    "- nearest neighbor classifiers using Wasserstein distance\n",
    "- support vector machines or other vector classifiers using the persistence landscapes of each image\n",
    "- k-means clustering on persistence landscapes"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Notebook 3_ Texture classification with cubical complexes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
