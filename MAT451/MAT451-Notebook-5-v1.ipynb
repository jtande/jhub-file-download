{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a4281e8",
   "metadata": {},
   "source": [
    "# Notebook 5: Looking for Klein bottles\n",
    "\n",
    "Inspired by the [paper](https://link.springer.com/article/10.1007/s11263-007-0056-x) by Carlsson et al., we are going to build part of the pipeline for finding the topology of 3x3 patches of pixels from images. \n",
    "\n",
    "_Spoilers_ We probably won't find the Klein bottle, since our analysis differs from that in the paper in a number of ways:\n",
    "- We are using one image and will eventually have about 300 patches to work with. Carlsson et al. start with 4 million patches from thousands of images and sample down to 10,000 at the last step.\n",
    "- Carlsson et al. deliberately throw in certain patches from non-dense regions using their set $Q$. We will not be doing that here.\n",
    "\n",
    "Nonetheless, I hope that this exercise gives some insight into what goes into this kind of analysis and also introduces you to `ripser`, which is far more efficient than `gudhi` for VR complexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b8188b-6799-41e8-9538-d058cecec428",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.22.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b32da6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ripser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e54c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install persim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f5e3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from ripser import ripser\n",
    "from persim import plot_diagrams\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef93c0f5",
   "metadata": {},
   "source": [
    "## Generating the 3x3 patch data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d73f21",
   "metadata": {},
   "source": [
    "In their paper, Carlsson et al. use a large database of images and eventually sample down before computing persistent homology. We are going to do everything to a single image, so we should not expect the same kind of results. However, we will at least grapple with what is required for this kind of analysis. The image I chose might be recognizable to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcae374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load image\n",
    "image = Image.open(\"./clocktower.jpeg\")\n",
    "#make grayscale\n",
    "gray = ImageOps.grayscale(image)\n",
    "array = np.array(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71948a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(array, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f0698a",
   "metadata": {},
   "source": [
    "We want to extract a lot of 3x3 patches and do some processing to them (namely take the log of each pixel value and subtract the mean). To make the code cleaner, I've wrapped that all up into a function below. Make sure you understand what this function is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93bf179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get3x3(x,y,array):\n",
    "    patch = np.array(\n",
    "        array[x:x+3, y:y+3],\n",
    "        dtype=float\n",
    "    ).flatten()\n",
    "    patch = np.log(1+patch)\n",
    "    patch = patch - np.mean(patch)\n",
    "    return patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc20d5f",
   "metadata": {},
   "source": [
    "To collect our patches, we'll choose 5000 random coordinate pairs and collect the 3x3 patches at those coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cba6aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2022) #this is so that it does the same thing every time, but you can remove it\n",
    "sample_x_coordinates = np.random.choice(range(array.shape[0]-3), 10000, replace=True)\n",
    "sample_y_coordinates = np.random.choice(range(array.shape[1]-3), 10000, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349f80ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = []\n",
    "for x, y in zip(sample_x_coordinates, sample_y_coordinates):\n",
    "    patches.append(get3x3(x,y,array))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a5f35b",
   "metadata": {},
   "source": [
    "## Pick high contrast patches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb534d9b",
   "metadata": {},
   "source": [
    "Each 3x3 patch has been flattened into a vector of length 9 by our function. We are now going to select the top 20% highest contrast patches from among the 5000. The contrast of a patch $\\vec{v}$ is defined in the paper as $\\vec{v}^{\\mathrm{T}} D \\vec{v}$ for a particular matrix $D$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434353bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.array([\n",
    "    [2,-1,0,-1,0,0,0,0,0],\n",
    "    [-1,3,-1,0,-1,0,0,0,0],\n",
    "    [0,-1,2,0,0,-1,0,0,0],\n",
    "    [-1,0,0,3,-1,0,-1,0,0],\n",
    "    [0,-1,0,-1,4,-1,0,-1,0],\n",
    "    [0,0,-1,0,-1,3,0,0,-1],\n",
    "    [0,0,0,-1,0,0,2,-1,0],\n",
    "    [0,0,0,0,-1,0,-1,3,-1],\n",
    "    [0,0,0,0,0,-1,0,-1,2]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3ee419",
   "metadata": {},
   "source": [
    "Let's order our patches by their contrast values. To do this we're going to use the Python function `sorted` in a particular way. The function `sorted` allows you to specify the key by which to sort the values you hand it. For example, you might want to sort words by length not by alphabetical order. Let's make a function that returns the contrast value first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065dc43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dnorm(patch):\n",
    "    return np.sqrt(patch.T @ D @ patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952f1bb1",
   "metadata": {},
   "source": [
    "Now we call `sorted` with `key=Dnorm` and also `reverse=True` so that we get it in descending order. After that we can take the top 1000 patches by constrast value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ae63f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_ordered_by_contrast = sorted(\n",
    "    patches,\n",
    "    key = lambda x: Dnorm(x),\n",
    "    reverse=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e6c81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_contrast_patches = patches_ordered_by_contrast[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e26833f",
   "metadata": {},
   "source": [
    "Let's look at the highest contrast patch just to get an idea. (We'll have to reshape it back to a 3x3 array to do so)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719dbafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(top_contrast_patches[0].reshape(3,3), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b2aa10",
   "metadata": {},
   "source": [
    "## A change of coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05c464d",
   "metadata": {},
   "source": [
    "We are now equipped with 1000 vectors of length 9. Carlsson et al. (following earlier [work](https://dash.harvard.edu/bitstream/handle/1/3637108/mumford_nonlinstatpatches.pdf?sequence=1) of Lee, Pederson and Mumford) normalize these vectors to have contrast value 1 and then apply a change of basis so that the vectors are arranged on the surface of the unit ball in $\\mathbb{R}^8$. In other words they do linear algebra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38b42f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize by contrast\n",
    "normalized_patches = [\n",
    "    v/Dnorm(v) for v in top_contrast_patches\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914391b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is our basis we're going to use\n",
    "e1 = 1/np.sqrt(6)*np.array([1,0,-1,1,0,-1,1,0,-1])\n",
    "e2 = 1/np.sqrt(6)*np.array([1,1,1,0,0,0,-1,-1,-1])\n",
    "e3 = 1/np.sqrt(54)*np.array([1,-2,1,1,-2,1,1,-2,1])\n",
    "e4 = 1/np.sqrt(54)*np.array([1,1,1,-2,-2,-2,1,1,1])\n",
    "e5 = 1/np.sqrt(8)*np.array([1,0,-1,0,0,0,-1,0,1])\n",
    "e6 = 1/np.sqrt(48)*np.array([1,0,-1,-2,0,2,1,0,-1])\n",
    "e7 = 1/np.sqrt(48)*np.array([1,-2,1,0,0,0,-1,2,-1])\n",
    "e8 = 1/np.sqrt(216)*np.array([1,-2,1,-2,4,-2,1,-2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799cafbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we build a matrix that changes basis (and dimension)\n",
    "gamma = np.diag([\n",
    "    1/np.linalg.norm(e)**2 for e in [e1,e2,e3,e4,e5,e6,e7,e8]\n",
    "])\n",
    "A = np.array([e1,e2,e3,e4,e5,e6,e7,e8]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f7e9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it's now time to apply the change of basis\n",
    "patches_in_R8 = [gamma@A.T@v for v in normalized_patches]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d5b13d",
   "metadata": {},
   "source": [
    "It's okay if you didn't follow everything above, but let's at least see the end result. Our new vectors should all have length 8, so let's check that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f45f2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(patches_in_R8[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36168187",
   "metadata": {},
   "source": [
    "They should also have length $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcf0245",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(patches_in_R8[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c300545",
   "metadata": {},
   "source": [
    "This means our vectors lie on the unit sphere in $\\mathbb{R}^8$, as required. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8030b54",
   "metadata": {},
   "source": [
    "## Density sampling\n",
    "We're still not done preprocessing. We want to take points only from the densest regions of the point cloud in $\\mathbb{R}^8$ that we can find. To do this, we pick a $k$ and compute the distance from each point to its $k^{th}$ nearest neighbor. Can you see how this value is low in dense regions and high in sparse regions? As before, we define a function which tells us the distance to the $k^{th}$ nearest neighbor and use it as a key to sort our vectors. It'll be a bit more efficient if we precompute all distances between all pairs of vectors*.\n",
    "\n",
    "_*this is not the most computationally efficient thing to do but it's the simplest_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eda1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_knn(vector):\n",
    "    distances_to_all_vectors = [np.linalg.norm(vector-v) for v in patches_in_R8]\n",
    "    return sorted(distances_to_all_vectors)[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a77744",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 15\n",
    "patches_sorted_by_density = sorted(\n",
    "    patches_in_R8,\n",
    "    key = distance_to_knn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a7d71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_from_high_density = patches_sorted_by_density[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eec172",
   "metadata": {},
   "source": [
    "We finally have the set of vectors we want to run persistent homology on. As a last step, let's organize our list of vectors into a single array like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a2427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.vstack(patches_from_high_density)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7150696",
   "metadata": {},
   "source": [
    "## Exercise 1: VR persistence using `ripser`\n",
    "\n",
    "Let's compute the VR persistence diagram for `data` now. For computing VR persistence on large point clouds, I recommend against `gudhi`. So for this exercise, compute and plot the 0 and 1 dimensional persistence (on one plot) of `data` using `ripser` following [this](https://ripser.scikit-tda.org/en/latest/notebooks/Basic%20Usage.html) simple example.\n",
    "\n",
    "If you do it right, you should see one clear $H_1$ point. This is in line with what [previous studies](https://diglib.eg.org/bitstream/handle/10.2312/SPBG.SPBG04.157-166/157-166.pdf?sequence=1&isAllowed=y) found with a small sample size and relatively low value of $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cea294",
   "metadata": {},
   "source": [
    "## Exercise 2: $H_2$ homology\n",
    "What about $H_2$? Run `ripser` again with the keyword `maxdim=2` and see what happens. How much longer did it take to run `ripser`? When I run it I don't get any $H_2$ points away from the diagonal, which shows that our sample size is not large enough to see the Klein bottle structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9fc340",
   "metadata": {},
   "source": [
    "## Exercise 3: Removing the density sampling\n",
    "\n",
    "Let's see whether the density sampling mattered. Repeat Exercise 1 but instead of using the vectors in `data`, use the vectors in `patches_in_R8` directly. What changes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fd938a",
   "metadata": {},
   "source": [
    "## Challenge questions\n",
    "\n",
    "- Choose your own image and repeat the above analysis. Might I suggest your favorite album cover?\n",
    "- Adjust the number of patches sampled (5000), the number of high contrast patches taken (1000), the value of $k$ (15) and/or the number of high density patches taken (300) and see if you see anything interesting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ceae79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
